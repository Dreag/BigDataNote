# The configuration file needs to define the sources, 
# the channels and the sinks.

### define agent
a3.sources = r3
a3.channels = c3
a3.sinks = k3


### define sources
#Spooling Directory Paths通过监听某个目录下的新增文件，
#并将文件的内容读取出来，实现日志信息的收集。实际生产
#中会结合log4j来使用。被传输结束的文件会修改后缀名，添
#加.COMPLETED后缀（可修改）
a3.sources.r3.type = spooldir
#指定监控目录
a3.sources.r3.spoolDir = /opt/cdh-5.3.6/flume-1.5.0-cdh5.3.6/spoollogs
#通过正则表达式排除.log文件，^$为全部检测
a3.sources.r3.ignorePattern = ^(.)*\\.log$
#指定文件传输完毕后的后缀
a3.sources.r3.fileSuffix = .delete

### define channels
a3.channels.c3.type = file
#指定存储文件信息路径（是否传输完毕等信息）
a3.channels.c3.checkpointDir = /opt/cdh-5.3.6/flume-1.5.0-cdh5.3.6/filechannel/checkpoint
a3.channels.c3.dataDirs = /opt/cdh-5.3.6/flume-1.5.0-cdh5.3.6/filechannel/data

### define sink
a3.sinks.k3.type = hdfs
#按日期生成目录
a3.sinks.k3.hdfs.path = hdfs://hadoop-senior.ibeifeng.com:8020/user/beifeng/flume/splogs/%Y%m%d
a3.sinks.k3.hdfs.fileType = DataStream 
a3.sinks.k3.hdfs.writeFormat = Text
a3.sinks.k3.hdfs.batchSize = 10
#开启使用服务器时间戳
a3.sinks.k3.hdfs.useLocalTimeStamp = true


### bind the soures and  sink to the channel
a3.sources.r3.channels = c3
a3.sinks.k3.channel = c3
