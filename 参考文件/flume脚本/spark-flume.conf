# The configuration file needs to define the sources, 
# the channels and the sinks.

### define agent
#定义resource
a1.sources = r1
#定义channel
a1.channels = c1
#定义sink
a1.sinks = k1

### define sources
#指定收集数据方式

a1.sources.r1.type = exec
a1.sources.r1.command = tail -f /home/zkj/spark-2.2.0-bin-hadoop2.7/README.md

a1.sources.r1.shell = /bin/bash -c

### define channels
#指定channel数据存储在内存中
a1.channels.c1.type = memory
#每次channel中寸多少个event
a1.channels.c1.capacity = 1000
#指定每次多少个event提交给sink
a1.channels.c1.transactionCapacity = 100

### define sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = MyDream
a1.sinks.k1.port = 9999

### bind the soures and  sink to the channel
#将resource和sink分别与channel绑定
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1